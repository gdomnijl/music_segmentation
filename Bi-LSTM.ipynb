{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Before feeding the 3-second audio samples into the bidirectional LSTM layer, \n",
    "# we will first need to feed it into the conv-relu-pool-flatten-(possibly fully-connected) layer.\n",
    "# This output of the convolution layer will be in the form X = (batch_size, time step, input_dim)\n",
    "# The output classes (e.g. Verse, Chorus) will be one-hot encoded and saved to y. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, devX, trainY, devY= train_test_split(X,Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bilstm(X, y, lstm_size=25, dropout_rate=0.25):\n",
    "    batch_size, n_timesteps, input_dim = X.shape\n",
    "    _, output_dim = y.shape[1]\n",
    "    \n",
    "    model.Sequential()\n",
    "    model.add(Bidirectional(LSTM(lstm_size, return_sequences=True), input_shape=(n_timesteps, input_dim)))\n",
    "    model.add(TimeDistributed(Dense(output_dim, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, modelName):\n",
    "    print (model.summary())\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=0, \n",
    "    mode='auto')\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(modelName, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "    \n",
    "    model.fit(trainX, trainY, \n",
    "            validation_data=(devX, devY),\n",
    "            epochs=30, batch_size=batch_size,\n",
    "            callbacks=[checkpoint, early_stopping])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
